---
title: "Homework 5"
author: "Jessica Flynn"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r set_up}
library(tidyverse)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1 

```{r read_homicide_data_raw}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") 
```

The raw data contains information on homicides in 50 large US cities. The variables include report date, victim's first and last name, as well as victim's race, age and sex. Additionally the database includes variables for city, state, latitude, longitude, and disposition of the case. The data has  `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns. 


Next, we will clean the data. Below, we create a variable `city_state` that merges the `city` and `state`variables into one variable separated by an underscore. Additionally, we create a variable called `resolved` which condenses `disposition` into 2 groups: unsolved and solved. Lastly, we remove the `city_state` of Tulsa_AL since this seems to be an error (Tulsa is on Oklahoma(OK))

```{r clean_data}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate( 
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved", 
      disposition =="Open/No arrest" ~ "unsolved", 
      disposition == "Closed by arrest" ~ "solved")
    ) %>%
  select(city_state, resolved ) %>% 
  filter(city_state != "Tulsa_AL")
```

Next, we  summarize by city to obtain the total number of homicides and the number of unsolved homicides in each.

```{r}
aggregate_df =
  homicide_df %>%
  group_by(city_state) %>% 
  summarize( 
    hom_total = n(), 
    hom_unsolved = sum(resolved == "unsolved"))

aggregate_df
```

We will look at Baltimore, MD and use the `prop.test` function to estimate the proportion of homicides that are unsolved. Below, we will see a tibble containing `estimate`, `conf.low` and `conf.high` which represent the estimated proportion of unsolved homicides and its lower and upper confidence interval bounds, respectively. 


```{r baltimore_prop_test}
test_output = 
  prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total))

test_output %>%
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```



Now, we will look at `prop.test` for each of the cities by using an iterative process. A resulting tibble will contain the same information as the tibble above for Baltimore_MD for each city.

```{r iterate_prop_test}
results_df = 
  aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)), 
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)

results_df
  
```

A plot of this information for each city is displayed below

```{r estimate_plot}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x =  element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Problem 2 

For problem 2 we will iterate to read in 20 csv files, each containing data for a separate subject from a longitudinal study. The study contained both a control and experimental arm.

We will create a tidy dataframe containing data from all participants, including the subject ID, arm, and value of the observations over the weeks.

```{r tidy_lda_data}
lda_data =
  tibble(
  path = list.files("lda_data")) %>%  
  mutate(files = map(path, ~read.csv(file = paste0("./lda_data/",.x)))) %>% 
  unnest(cols = c(files)) %>% 
  pivot_longer(
    cols = week_1:week_8, 
    names_to = "week", 
    names_prefix = "week_", 
    names_transform = list(week = as.numeric)) %>% 
  separate(
    path,
    into = c("arm", "subject"),
    sep = "_") %>%
  mutate(
    arm = case_when(arm == "con" ~"control", 
                    arm == "exp" ~ "experimental"), 
    subject =  str_sub(subject, end = -5))

```


Below, we see a  spaghetti plot showing observations on each subject over time for each arm. 

```{r spaghetti_plot}
lda_data %>% 
  ggplot(aes(x = week, y = value, color = subject)) +
  geom_line(aes(group = subject)) + 
  facet_grid(~arm) +
  labs(x = "Week", 
       y = "Observation")

```


We notice that in the control group, the values stay mostly stable across the weeks. However, for the experimental group, there is a steady increase in values across the weeks. 

## Problem 3 




